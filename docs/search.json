[
  {
    "objectID": "day2.html",
    "href": "day2.html",
    "title": "Day 2",
    "section": "",
    "text": "Yesterday we covered:\n\nHow to use Unix.\nHow to get onto HAWK.\nHow to fetch the Github repository and download the resources.\nHow to execute the scrnaseq nextflow pipeline on Hawk.\n\n\n\n\n\n\nThe output from the nextflow execution run is stored under results/cellranger_count_1k_mouse_kidney_CNIK_3pv3\nLogin to your Hawk account and access the folder:\n\ncd /scratch/c.123456/scrnaseq-course/scrnaseq/results\n\ncd cellranger_count_1k_mouse_kidney_CNIK_3pv3\n\n\n\n\nYou can skip this step if you are working on RStudio Server.\nOnce the counts are generated using nextflow pipeline, download the data onto your personal computer.\nFor this, you will need to use Filezilla to copy the files from remote onto your local machine.\nFollow the steps below:\n\n\nType in the Host: hawklogin.cf.ac.uk\nUsername: \nPassword: \nPort: 22\n\n\nClick on Quickconnect\nNavigate to the folder scrnaseq-course/scrnaseq/results\nCreate a folder on your local machine, called scrnaseq-nextflow.\nCreate 4 folders within scrnaseq-nextflow folder:\n\nbin\ninput\noutput\nresources\n\nNow, Drag and Drop the files from the results folder in the remote server to your input folder within scrnaseq-nextflow folder on your local machine.\nOnce the files are copied, these should be visible on your local machine under input folder.\n\n\n\n\n\n\nOnce the counts have been downloaded into the input folder on your local machine, Start RStudio on Mac/Windows.\n\n\n\nClick on New File –&gt; R Markdown...\n\n\n\nThis is will open an Untiltled file on the top-left hand side.\n\n\n\nDelete lines from 7 until 29 except first 5-6 lines.\n\n\n\n\n\nCopy the line in your markdown document:\n\n\n\nCode\n# load libraries\nlibrary(Seurat)\n\n\nLoading required package: SeuratObject\n\n\nLoading required package: sp\n\n\n'SeuratObject' was built under R 4.5.0 but the current version is\n4.5.2; it is recomended that you reinstall 'SeuratObject' as the ABI\nfor R may have changed\n\n\n\nAttaching package: 'SeuratObject'\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, t\n\n\n\nPress the green arrow key on line 7 which says Run Current Chunk to load the Seurat library.\n\n\n\n\n\n\nWe start by reading in the data. The Read10X() function reads in the output of the cellranger pipeline from 10X, returning a unique molecular identified (UMI) count matrix.\nThe values in this matrix represent the number of molecules for each feature (i.e. gene; row) that are detected in each cell (column).\n\n# Load the 1k mouse kidney dataset\ndat2 &lt;- Read10X(data.dir = \"input/filtered_feature_bc_matrix/\")\n\nWe next use the count matrix to create a Seurat object.\n\n# Initialize the Seurat object with the raw (non-normalized data).\ndat2Obj &lt;- CreateSeuratObject(counts = dat2, project = \"1KmouseKidney\", min.cells = 3, min.features = 200)\n\ndat2Obj\n\n\n\nSeurat allows you to easily explore QC metrics and filter cells based on any user-defined criteria.\nThese includes:\n\nThe number of unique genes detected in each cell.\n\nLow-quality cells or empty droplets will often have very few genes\nCell doublets or multiplets may exhibit an aberrantly high gene count\n\nThe percentage of reads that map to the mitochondrial genome.\n\nLow-quality / dying cells often exhibit extensive mitochondrial contamination\nWe calculate mitochondrial QC metrics with the PercentageFeatureSet() function\nWe use the set of all genes starting with MT- or mt- as a set of mitochondrial genes\n\n\n\n# The [[ operator can add columns to object metadata.\ndat2Obj[[\"percent.mt\"]] &lt;- PercentageFeatureSet(dat2Obj, pattern = \"^mt-\")\n\nTo visualize QC metrics, we use VlnPlot() function.\n\n# Visualize QC metrics as a violin plot\nVlnPlot(dat2Obj, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), ncol = 3)\n\nTry using ^MT- as pattern. What do you get?\ndat2Obj[[\"percent.mt\"]] &lt;- PercentageFeatureSet(dat2Obj, pattern = \"^MT-\")\n\nNext, you can plot a FeatureScatter plot for visualising feature-feature relationships.\n\n# Plot FeatureScatter plot\nplot1 &lt;- FeatureScatter(dat2Obj, feature1 = \"nCount_RNA\", feature2 = \"percent.mt\")\nplot2 &lt;- FeatureScatter(dat2Obj, feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\")\nplot1 + plot2\n\n\nNow, we will filter cells that have unique feature counts over 9000 or less than 200\nWe filter cells that have &gt;5% mitochondrial counts\n\ndat2FilteredObj &lt;- subset(dat2Obj, subset = nFeature_RNA &gt; 200 & nFeature_RNA &lt; 9000 &  percent.mt &lt; 5)\n\ndat2FilteredObj\n# An object of class Seurat \n# 18321 features across 1235 samples within 1 assay \n# Active assay: RNA (18321 features, 0 variable features)\n#  1 layer present: counts\nLets break it down: - nFeature_RNA &gt; 200: Keeps cells that have more than 200 detected genes (features). This removes low-quality cells or empty droplets. - Feature_RNA &lt; 9000: Removes cells with too many detected genes, which might indicate doublets (two cells captured in one droplet). - percent.mt &lt; 5: Filters out cells where mitochondrial gene percentage is greater than 5%. High mitochondrial content often indicates damaged or dying cells.\n\nWith this command, the number of cells reduces to 1235.\n\n\n\n\n\n\nAfter removing unwanted cells from the dataset, the next step is to normalize the data.\nBy default, we employ a global-scaling normalization method LogNormalize that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result.\nNormalized values are stored in dat2NormalisedObj[[\"RNA\"]]$data\n\ndat2NormalisedObj &lt;- NormalizeData(object = dat2FilteredObj, normalization.method = \"LogNormalize\", scale.factor = 10000)\n\nThe use of SCTransform replaces the need to run NormalizeData, FindVariableFeatures, or ScaleData.\n\n\n\n\n\nWe next calculate a subset of features (genes) that exhibit high cell-to-cell variation in the dataset.\nThese are the features those are highly expressed in some cells, and lowly expressed in others.\nIt has been found Brennecke et al. Nat Methods.2013 that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets.\n\ndat2Normalised2Obj &lt;- FindVariableFeatures(dat2NormalisedObj, selection.method = \"vst\", nfeatures = 2000)\ntop10 &lt;- head(VariableFeatures(dat2Normalised2Obj), 10)\nplot3 &lt;- VariableFeaturePlot(dat2Normalised2Obj)\nplot4 &lt;- LabelPoints(plot = plot3, points = top10, repel = TRUE)\nCombinePlots(plots = list(plot3, plot4))\n\n\n\n\n\nThe ScaleData function in Seurat is used to normalize and scale gene expression values across cells.\nAdditionally, it can regress out unwanted sources of variation, such as sequencing depth (nUMI) or mitochondrial gene percentage (percent.mito), helping to remove technical artifacts.\nBy default, only variable features are scaled.\nBut if you observe, in out script, we have used rownames(dat2Normalised2Obj) which applies scaling to all genes which is stored in all.genes object.\nThis is then applied to ScaleData function which uses all.genes as features for scaling.\n\nall.genes &lt;- rownames(dat2Normalised2Obj)\ndat2ScaledObj &lt;- ScaleData(object = dat2Normalised2Obj, features = all.genes)\n\n\n\nTo remove unwanted sources of variation from a single-cell dataset, such as “percent.mt”, use “vars.to.regress” to include these:\n\ndat2ScaledObj &lt;- ScaleData(object = dat2Normalised2Obj, features = all.genes, vars.to.regress = \"percent.mt\")\n\n\n\n\n\nNext we perform PCA on the scaled data.\nBy default, only the previously determined variable features are used as input, but can be defined using features argument if you wish to choose a different subset.\n\ndat2Scaled2Obj &lt;- RunPCA(object = dat2ScaledObj, features = VariableFeatures(object = dat2ScaledObj), do.print = TRUE, ndims.print = 1:5, nfeatures.print = 5)\n\nThis command uses only the highly variable genes (VariableFeatures(object = dat2ScaledObj)) instead of all genes to reduce noise and improve clustering.\ndo.print = TRUE prints the top genes contributing to each principal component (PC).\npcs.print = 1:5 displays the results for PC1 to PC5 (i.e., the first five principal components).\nPC1 (Principal Component 1) is the most important axes of variation.\nPC2, PC3, PC4, etc. explain additional variation in the data.\nTop Positive Genes (e.g., Ldb2, Ebf1, Prkg1, Meis2) are more highly expressed in one subset of cells.\nTop Negative Genes (e.g., Slc27a2, Keg1, Sugct) are more highly expressed in another subset.\nPC1 may capture a major biological signal, such as cell type differences.\nIf PC2 separates a different cell population, it might represent a different biological process, like a cell cycle state or differentiation.\nDimHeatmap() allows for easy exploration of the primary sources of heterogeneity in a dataset, and can be useful when trying to decide which PCs to include for further downstream analyses.\n\nDimHeatmap(\n    object = dat2Scaled2Obj, \n    dims = 1, \n    balanced = TRUE\n)\n\n\nNow, use dims 1 to 15 to plot 15 PCs to observe which PCs contribute to sources of variation in the dataset.\n\nDimHeatmap(\n    object = dat2Scaled2Obj, \n    dims = 1:15, \n    balanced = TRUE\n)\n\n\n\n\n\nAfter running PCA using RunPCA(), you need to determine how many PCs to retain for clustering and downstream analysis.\nOne common method is using the Elbow Plot.\nThe top principal components represents highest variations in the dataset.\nSo, how many components should we choose to include? 10? 20? 100?\nIn ‘Elbow plot’ it ranks principle components based on the percentage of variance explained by each one.\n\nElbowPlot(dat2Scaled2Obj)\n\n\nIf we are considering going with the default settings with ndims = 20, then we can clearly see that at the elbow point is at PC 11 which accounts for most variation in the dataset.\nHowever, if we choose to include ndims = 50, then the elbow plot changes and includes 50 PCs.\n\nElbowPlot(dat2Scaled2Obj, ndims = 50)\n\n\nNow, this gives us a much broader picture and also shows more PCs are contributing to variation beyond PC 11.\nWith this plot, we can keep the value between PC 21-25.\nIn this tutorial, I have chosen PC 25 to stretch the limit and include smaller variance. But the value of 21 will also work fine.\n\n\n\n\n\nSeurat applies a graph-based clustering approach, called Shared Nearest Neighbors (SNN).\nHow the SNN Score is Computed:\n\nIf cell A’s neighbor list and cell B’s neighbor list share many cells, they are likely to be in the same cluster.\nThe SNN score (edge weight) is higher if two cells have more shared neighbors.\n\nExample:\n\nCell A’s neighbors: {B, C, D, E}\nCell B’s neighbors: {A, C, D, F}\nCell A and Cell B share: {C, D}\nSNN score = Number of shared neighbors / Minimum kNN list size\nSNN score = 2 / 4 = 0.5\n\nIf two cells share many of their nearest neighbors, their SNN score is high, and they are more likely to belong to the same cluster.\n\n\n\nSo, the first step is performed using the FindNeighbors() function, and takes as input the previously defined dimensionality of the dataset (first 25 PCs).\nTo cluster the cells, we next apply modularity optimization techniques such as the Louvain algorithm (default) or SLM to iteratively group cells together.\nThe FindClusters() function implements this procedure, and contains a resolution parameter that sets the ‘granularity’ of the downstream clustering, with increased values leading to a greater number of clusters.\n\nRun the following commands:\nseuratFindNeighbors &lt;- FindNeighbors(\n    dat2Scaled2Obj,\n    reduction = \"pca\",\n    dims = 1:25,\n    do.plot = FALSE,\n    graph.name = NULL,\n    k.param = 30\n)\n\nseuratFindClusters &lt;- FindClusters(object = seuratFindNeighbors)\n\n\n\n\nSeurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets.\nThe goal of these algorithms is to learn underlying structure in the dataset, in order to place similar cells together in low-dimensional space.\nTherefore, cells that are grouped together within graph-based clusters determined above should co-localize on these dimension reduction plots.\n\ndat2UMAP &lt;- RunUMAP(seuratFindClusters, reduction = \"pca\", dims = 1:25, n.neighbors = 30L, min.dist = 0.3, seed.use = 123456L)\n\nIf you see that we have used 25 PCs and n.neighbors as 30\nn.neighbors defines the number of nearest neighbors considered when constructing the UMAP graph.\nLarger values capture broader structures, while smaller values focus on finer details.\n\n\n\n\n\n\n\n\n\nn.neighbors Value\nEffect on UMAP\nWhen to Use?\n\n\n\n\nLow (5-15)\nCaptures local structure, fine details\nSmall datasets, cluster refinement\n\n\nDefault (30)\nBalanced between local and global structure\nGeneral use case\n\n\nHigh (50-100)\nPreserves global relationships, reduces fragmentation\nLarge datasets, broader clusters\n\n\n\nTo generate UMAP, run the following command:\nDimPlot(dat2UMAP, reduction = \"umap\")\n\n\n\n\n\nIn scRNA-seq experiments, doublets are artifactual libraries generated from two cells.\nDoublets are defined when two or more cells are mistakenly treated as a single cell.\nThey typically arise due to errors in cell sorting or capture, especially in droplet-based protocols involving thousands of cells.\nIn this workshop, we will be using DoubletFinder.\nIt is a tool used to detect and remove doublets (artificially merged cells) in scRNA-seq data.\nBelow is a step-by-step guide to doublet detection and removal in Seurat using DoubletFinder.\n\nStep 1: Install and Load Required Packages\nremotes::install_github('chris-mcginnis-ucsf/DoubletFinder')\nOnce the package is installed, the load the library.\nlibrary(DoubletFinder)\nStep 2: Parameter Sweeping for pK Selection\nSweep a range of parameters to find the optimal pK.\nsweep.res.list &lt;- paramSweep(dat2UMAP, PCs = 1:20, sct = TRUE)\nsweep.stats &lt;- summarizeSweep(sweep.res.list, GT = FALSE)\nbcmvn &lt;- find.pK(sweep.stats)\npk &lt;- as.numeric(as.vector(bcmvn$pK)[which.max(bcmvn$BCmetric)])\n\nparamSweep(): Tests multiple pK (parameter K) values using PCs 1 to 20.\nsummarizeSweep(): Summarizes results into a dataframe.\nfind.pK(): Finds the best pK using a “BCmetric” score.\nwhich.max(bcmvn$BCmetric): Selects the pK value with the highest BCmetric, as this gives the best separation between doublets and singlets.\n\nWhy do we need pK?\n\npK is a clustering resolution parameter that affects doublet detection.\nA higher BCmetric means better performance of a given pK.\n\nStep 3: Estimate the Expected Number of Doublets\nannotations &lt;- dat2UMAP@active.ident\nhomotypic.prop &lt;- modelHomotypic(annotations)\nnExp_poi &lt;- round(0.076 * length(dat2UMAP@active.ident))\nnExp_poi.adj &lt;- round(nExp_poi * (1 - homotypic.prop))\n\nmodelHomotypic(annotations): Estimates homotypic doublets (cells of the same type that are mistakenly identified as a doublet).\nnExp_poi &lt;- round(0.076 * length(p1tumorFilteredObj@active.ident)):\n\nUses 10X Genomics’ doublet rate formula: ~7.6% (0.076) × number of cells.\nThis gives the expected number of doublets (nExp_poi) in the dataset.\n\nnExp_poi.adj &lt;- round(nExp_poi * (1 - homotypic.prop))\n\nAdjusts for homotypic doublets to avoid over-filtering.\n\n\nWhy adjust for homotypic proportion?\n\nIf cells in a cluster are mostly from the same cell type, they might be misclassified as doublets.\nThis adjustment prevents over-filtering of true biological clusters.\n\nStep 4: Run DoubletFinder (First Pass)\nseuratDoublet &lt;- doubletFinder(dat2UMAP, PCs = 1:20, pN = 0.25, pK = pk, \n                               nExp = nExp_poi, reuse.pANN = FALSE, sct = TRUE)\n\nThis step assigns a probability score (pANN) to each cell, indicating how likely it is a doublet.\n\nStep 5: Prepare for Second Pass\npANN_String &lt;- paste(\"pANN_0.25_\", pk, \"_\", list(nExp_poi), sep=\"\")\n\nCreates a string name for the pANN column, which stores doublet probability scores.\n\nStep 6: Run DoubletFinder (Second Pass - Adjusted for Homotypic Doublets)\ndat2UMAPDoublet &lt;- doubletFinder(seuratDoublet, PCs = 1:10, pN = 0.25, pK = pk, \n                                        nExp = nExp_poi.adj, reuse.pANN = pANN_String)\n\nThe first pass identifies all doublets.\nThe second pass refines the classification by removing homotypic doublets.\n\nStep 7: Append doublets column in metadata\n# Use this format: DF.classifications_pN_pk_nExp_poi\n\n# Find out pk value\nprint(pk)\n\n# Find out nExp_poi value\nprint(nExp_poi)\n\n# Replace the DF.classifications_pN_pk_nExp_poi with the above values\n\n# For example, if pk is 0.24 and nExp_poi is 134, then execute the following command\n\nclassificationsCol &lt;- dat2UMAPDoublet@meta.data[\"DF.classifications_0.25_0.24_134\"]\n\ndat2UMAPDoublet@meta.data[,\"DF_hi.lo\"] &lt;- classificationsCol[1]\n\nNow, construct a UMAP displaying the Doublets and Singlets.\nYou can also generate Violin plot displaying the same information.\n\n\n\n\nRemove the doublets and select Singlets by performing the following command:\ndat2UMAPSinglets &lt;- subset(dat2UMAPDoublet, subset = DF_hi.lo == \"Singlet\")\nOnce the doublets are removed and singlets are selected, then re-run the following steps as performed above:\nsingletsNormalisedObj &lt;- NormalizeData(object = dat2UMAPSinglets, normalization.method = \"LogNormalize\", scale.factor = 10000)\nsingletsNormalised2Obj &lt;- FindVariableFeatures(singletsNormalisedObj, selection.method = \"vst\", nfeatures = 2000)\nall.genes &lt;- rownames(singletsNormalised2Obj)\nsingletsScaledObj &lt;- ScaleData(object = singletsNormalised2Obj, features = all.genes)\nsingletsScaled2Obj &lt;- RunPCA(object = singletsScaledObj, features = VariableFeatures(object = singletsScaledObj), do.print = TRUE, ndims.print = 1:5, nfeatures.print = 5)\nElbowPlot(singletsScaled2Obj, ndims = 50)\nseuratFindNeighbors &lt;- FindNeighbors(\n    singletsScaled2Obj,\n    reduction = \"pca\",\n    dims = 1:25,\n    do.plot = FALSE,\n    graph.name = NULL,\n    k.param = 30\n)\nsingletsFindClusters &lt;- FindClusters(object = singletsFindNeighbors)\nsingletsUMAP &lt;- RunUMAP(singletsFindClusters, reduction = \"pca\", dims = 1:25, n.neighbors = 30L, min.dist = 0.3, seed.use = 123456L)\nOnce the pre-processing steps are finished, construct the UMAP using the DimPlot function.\nDimPlot(singletsUMAP, reduction = \"umap\")\n\n\n\n\nThere are several data visualisation methods and functions in Seurat which are used for visualising marker feature expression.\nThis can be achieved using:\n\nFeaturePlot()\nDotPlot()\nVlnPlot()\nRidgePlot()\nDimPlot()\nDoHeatmap()\n\n\n\n\n\nThe FeaturePlot() function in Seurat is used to visualize the expression of one or more genes (features) on a UMAP.\nIt helps in identifying the spatial distribution of gene expression across clusters or cell populations.\n\nFeaturePlot(dat2UMAP, features = c(\"Slc26a4\", \"Slc34a1\", \"Slc8a1\", \"Ptpro\", \"Csmd1\", \"Top2a\"))\n\n\n\n\n\nThe DotPlot() function in Seurat is used to visualize the expression levels of multiple genes across different clusters in a dot plot format.\nIt is particularly useful for comparing marker gene expression across cell clusters and assigning cell types.\n\ngenes = c(\"Slc26a4\", \"Slc34a1\", \"Slc8a1\", \"Ptpro\", \"Csmd1\", \"Top2a\")\nDotPlot(dat2UMAP, features = genes) + RotatedAxis()\n\n\n\n\n\nThe VlnPlot() function in Seurat creates violin plots to visualize the distribution of gene expression levels across different clusters or groups of cells.\nIt helps in identifying differences in gene expression between clusters.\n\ngenes = c(\"Slc26a4\", \"Slc34a1\", \"Slc8a1\", \"Ptpro\", \"Csmd1\", \"Top2a\")\nVlnPlot(dat2UMAP, features = genes)\n\n\n\n\n\nThe RidgePlot() function in Seurat generates ridge plots to visualize the distribution of gene expression across different clusters or groups of cells.\nIt is useful for comparing the expression levels of genes in different cell populations.\n\ngenes = c(\"Slc26a4\", \"Slc34a1\", \"Slc8a1\", \"Ptpro\", \"Csmd1\", \"Top2a\")\nRidgePlot(dat2UMAP, features = genes, ncol = 2)\n\n\n\n\n\nThe DimPlot() function in Seurat is used to visualize cells in a reduced dimensional space (e.g., UMAP, t-SNE, or PCA) and color them based on their cluster identity or metadata attributes.\nIt is useful for identifying and interpreting cell populations in single-cell RNA-seq analysis.\n\nSyntax:\nDimPlot(object, reduction = \"umap\", group.by = \"ident\", label = TRUE, pt.size = 1)\nFor example-\nDimPlot(dat2UMAP, reduction = \"pca\")\n\n\n\n\n\nThe DoHeatmap() function in Seurat is used to generate a heatmap of gene expression across different cell clusters or groups.\nIt is particularly useful for visualizing the expression patterns of top marker genes across clusters.\n\nDoHeatmap(dat2UMAP, features = VariableFeatures(dat2UMAP)[1:100], cells = 1:500, size = 4,\n          angle = 90) + NoLegend()"
  },
  {
    "objectID": "day2.html#recap-from-day-1",
    "href": "day2.html#recap-from-day-1",
    "title": "Day 2",
    "section": "",
    "text": "Yesterday we covered:\n\nHow to use Unix.\nHow to get onto HAWK.\nHow to fetch the Github repository and download the resources.\nHow to execute the scrnaseq nextflow pipeline on Hawk."
  },
  {
    "objectID": "day2.html#outputs-from-the-nextflow-pipeline",
    "href": "day2.html#outputs-from-the-nextflow-pipeline",
    "title": "Day 2",
    "section": "",
    "text": "The output from the nextflow execution run is stored under results/cellranger_count_1k_mouse_kidney_CNIK_3pv3\nLogin to your Hawk account and access the folder:\n\ncd /scratch/c.123456/scrnaseq-course/scrnaseq/results\n\ncd cellranger_count_1k_mouse_kidney_CNIK_3pv3"
  },
  {
    "objectID": "day2.html#downloading-data-for-analysis-in-seurat-for-analysis-on-rstudio-on-local-system",
    "href": "day2.html#downloading-data-for-analysis-in-seurat-for-analysis-on-rstudio-on-local-system",
    "title": "Day 2",
    "section": "",
    "text": "You can skip this step if you are working on RStudio Server.\nOnce the counts are generated using nextflow pipeline, download the data onto your personal computer.\nFor this, you will need to use Filezilla to copy the files from remote onto your local machine.\nFollow the steps below:\n\n\nType in the Host: hawklogin.cf.ac.uk\nUsername: \nPassword: \nPort: 22\n\n\nClick on Quickconnect\nNavigate to the folder scrnaseq-course/scrnaseq/results\nCreate a folder on your local machine, called scrnaseq-nextflow.\nCreate 4 folders within scrnaseq-nextflow folder:\n\nbin\ninput\noutput\nresources\n\nNow, Drag and Drop the files from the results folder in the remote server to your input folder within scrnaseq-nextflow folder on your local machine.\nOnce the files are copied, these should be visible on your local machine under input folder."
  },
  {
    "objectID": "day2.html#processing-scrnaseq-data-1k_mouse_kidney_cnik_3pv3-in-seurat",
    "href": "day2.html#processing-scrnaseq-data-1k_mouse_kidney_cnik_3pv3-in-seurat",
    "title": "Day 2",
    "section": "",
    "text": "Once the counts have been downloaded into the input folder on your local machine, Start RStudio on Mac/Windows.\n\n\n\nClick on New File –&gt; R Markdown...\n\n\n\nThis is will open an Untiltled file on the top-left hand side.\n\n\n\nDelete lines from 7 until 29 except first 5-6 lines.\n\n\n\n\n\nCopy the line in your markdown document:\n\n\n\nCode\n# load libraries\nlibrary(Seurat)\n\n\nLoading required package: SeuratObject\n\n\nLoading required package: sp\n\n\n'SeuratObject' was built under R 4.5.0 but the current version is\n4.5.2; it is recomended that you reinstall 'SeuratObject' as the ABI\nfor R may have changed\n\n\n\nAttaching package: 'SeuratObject'\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, t\n\n\n\nPress the green arrow key on line 7 which says Run Current Chunk to load the Seurat library.\n\n\n\n\n\n\nWe start by reading in the data. The Read10X() function reads in the output of the cellranger pipeline from 10X, returning a unique molecular identified (UMI) count matrix.\nThe values in this matrix represent the number of molecules for each feature (i.e. gene; row) that are detected in each cell (column).\n\n# Load the 1k mouse kidney dataset\ndat2 &lt;- Read10X(data.dir = \"input/filtered_feature_bc_matrix/\")\n\nWe next use the count matrix to create a Seurat object.\n\n# Initialize the Seurat object with the raw (non-normalized data).\ndat2Obj &lt;- CreateSeuratObject(counts = dat2, project = \"1KmouseKidney\", min.cells = 3, min.features = 200)\n\ndat2Obj\n\n\n\nSeurat allows you to easily explore QC metrics and filter cells based on any user-defined criteria.\nThese includes:\n\nThe number of unique genes detected in each cell.\n\nLow-quality cells or empty droplets will often have very few genes\nCell doublets or multiplets may exhibit an aberrantly high gene count\n\nThe percentage of reads that map to the mitochondrial genome.\n\nLow-quality / dying cells often exhibit extensive mitochondrial contamination\nWe calculate mitochondrial QC metrics with the PercentageFeatureSet() function\nWe use the set of all genes starting with MT- or mt- as a set of mitochondrial genes\n\n\n\n# The [[ operator can add columns to object metadata.\ndat2Obj[[\"percent.mt\"]] &lt;- PercentageFeatureSet(dat2Obj, pattern = \"^mt-\")\n\nTo visualize QC metrics, we use VlnPlot() function.\n\n# Visualize QC metrics as a violin plot\nVlnPlot(dat2Obj, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), ncol = 3)\n\nTry using ^MT- as pattern. What do you get?\ndat2Obj[[\"percent.mt\"]] &lt;- PercentageFeatureSet(dat2Obj, pattern = \"^MT-\")\n\nNext, you can plot a FeatureScatter plot for visualising feature-feature relationships.\n\n# Plot FeatureScatter plot\nplot1 &lt;- FeatureScatter(dat2Obj, feature1 = \"nCount_RNA\", feature2 = \"percent.mt\")\nplot2 &lt;- FeatureScatter(dat2Obj, feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\")\nplot1 + plot2\n\n\nNow, we will filter cells that have unique feature counts over 9000 or less than 200\nWe filter cells that have &gt;5% mitochondrial counts\n\ndat2FilteredObj &lt;- subset(dat2Obj, subset = nFeature_RNA &gt; 200 & nFeature_RNA &lt; 9000 &  percent.mt &lt; 5)\n\ndat2FilteredObj\n# An object of class Seurat \n# 18321 features across 1235 samples within 1 assay \n# Active assay: RNA (18321 features, 0 variable features)\n#  1 layer present: counts\nLets break it down: - nFeature_RNA &gt; 200: Keeps cells that have more than 200 detected genes (features). This removes low-quality cells or empty droplets. - Feature_RNA &lt; 9000: Removes cells with too many detected genes, which might indicate doublets (two cells captured in one droplet). - percent.mt &lt; 5: Filters out cells where mitochondrial gene percentage is greater than 5%. High mitochondrial content often indicates damaged or dying cells.\n\nWith this command, the number of cells reduces to 1235.\n\n\n\n\n\n\nAfter removing unwanted cells from the dataset, the next step is to normalize the data.\nBy default, we employ a global-scaling normalization method LogNormalize that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result.\nNormalized values are stored in dat2NormalisedObj[[\"RNA\"]]$data\n\ndat2NormalisedObj &lt;- NormalizeData(object = dat2FilteredObj, normalization.method = \"LogNormalize\", scale.factor = 10000)\n\nThe use of SCTransform replaces the need to run NormalizeData, FindVariableFeatures, or ScaleData.\n\n\n\n\n\nWe next calculate a subset of features (genes) that exhibit high cell-to-cell variation in the dataset.\nThese are the features those are highly expressed in some cells, and lowly expressed in others.\nIt has been found Brennecke et al. Nat Methods.2013 that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets.\n\ndat2Normalised2Obj &lt;- FindVariableFeatures(dat2NormalisedObj, selection.method = \"vst\", nfeatures = 2000)\ntop10 &lt;- head(VariableFeatures(dat2Normalised2Obj), 10)\nplot3 &lt;- VariableFeaturePlot(dat2Normalised2Obj)\nplot4 &lt;- LabelPoints(plot = plot3, points = top10, repel = TRUE)\nCombinePlots(plots = list(plot3, plot4))\n\n\n\n\n\nThe ScaleData function in Seurat is used to normalize and scale gene expression values across cells.\nAdditionally, it can regress out unwanted sources of variation, such as sequencing depth (nUMI) or mitochondrial gene percentage (percent.mito), helping to remove technical artifacts.\nBy default, only variable features are scaled.\nBut if you observe, in out script, we have used rownames(dat2Normalised2Obj) which applies scaling to all genes which is stored in all.genes object.\nThis is then applied to ScaleData function which uses all.genes as features for scaling.\n\nall.genes &lt;- rownames(dat2Normalised2Obj)\ndat2ScaledObj &lt;- ScaleData(object = dat2Normalised2Obj, features = all.genes)\n\n\n\nTo remove unwanted sources of variation from a single-cell dataset, such as “percent.mt”, use “vars.to.regress” to include these:\n\ndat2ScaledObj &lt;- ScaleData(object = dat2Normalised2Obj, features = all.genes, vars.to.regress = \"percent.mt\")\n\n\n\n\n\nNext we perform PCA on the scaled data.\nBy default, only the previously determined variable features are used as input, but can be defined using features argument if you wish to choose a different subset.\n\ndat2Scaled2Obj &lt;- RunPCA(object = dat2ScaledObj, features = VariableFeatures(object = dat2ScaledObj), do.print = TRUE, ndims.print = 1:5, nfeatures.print = 5)\n\nThis command uses only the highly variable genes (VariableFeatures(object = dat2ScaledObj)) instead of all genes to reduce noise and improve clustering.\ndo.print = TRUE prints the top genes contributing to each principal component (PC).\npcs.print = 1:5 displays the results for PC1 to PC5 (i.e., the first five principal components).\nPC1 (Principal Component 1) is the most important axes of variation.\nPC2, PC3, PC4, etc. explain additional variation in the data.\nTop Positive Genes (e.g., Ldb2, Ebf1, Prkg1, Meis2) are more highly expressed in one subset of cells.\nTop Negative Genes (e.g., Slc27a2, Keg1, Sugct) are more highly expressed in another subset.\nPC1 may capture a major biological signal, such as cell type differences.\nIf PC2 separates a different cell population, it might represent a different biological process, like a cell cycle state or differentiation.\nDimHeatmap() allows for easy exploration of the primary sources of heterogeneity in a dataset, and can be useful when trying to decide which PCs to include for further downstream analyses.\n\nDimHeatmap(\n    object = dat2Scaled2Obj, \n    dims = 1, \n    balanced = TRUE\n)\n\n\nNow, use dims 1 to 15 to plot 15 PCs to observe which PCs contribute to sources of variation in the dataset.\n\nDimHeatmap(\n    object = dat2Scaled2Obj, \n    dims = 1:15, \n    balanced = TRUE\n)\n\n\n\n\n\nAfter running PCA using RunPCA(), you need to determine how many PCs to retain for clustering and downstream analysis.\nOne common method is using the Elbow Plot.\nThe top principal components represents highest variations in the dataset.\nSo, how many components should we choose to include? 10? 20? 100?\nIn ‘Elbow plot’ it ranks principle components based on the percentage of variance explained by each one.\n\nElbowPlot(dat2Scaled2Obj)\n\n\nIf we are considering going with the default settings with ndims = 20, then we can clearly see that at the elbow point is at PC 11 which accounts for most variation in the dataset.\nHowever, if we choose to include ndims = 50, then the elbow plot changes and includes 50 PCs.\n\nElbowPlot(dat2Scaled2Obj, ndims = 50)\n\n\nNow, this gives us a much broader picture and also shows more PCs are contributing to variation beyond PC 11.\nWith this plot, we can keep the value between PC 21-25.\nIn this tutorial, I have chosen PC 25 to stretch the limit and include smaller variance. But the value of 21 will also work fine.\n\n\n\n\n\nSeurat applies a graph-based clustering approach, called Shared Nearest Neighbors (SNN).\nHow the SNN Score is Computed:\n\nIf cell A’s neighbor list and cell B’s neighbor list share many cells, they are likely to be in the same cluster.\nThe SNN score (edge weight) is higher if two cells have more shared neighbors.\n\nExample:\n\nCell A’s neighbors: {B, C, D, E}\nCell B’s neighbors: {A, C, D, F}\nCell A and Cell B share: {C, D}\nSNN score = Number of shared neighbors / Minimum kNN list size\nSNN score = 2 / 4 = 0.5\n\nIf two cells share many of their nearest neighbors, their SNN score is high, and they are more likely to belong to the same cluster.\n\n\n\nSo, the first step is performed using the FindNeighbors() function, and takes as input the previously defined dimensionality of the dataset (first 25 PCs).\nTo cluster the cells, we next apply modularity optimization techniques such as the Louvain algorithm (default) or SLM to iteratively group cells together.\nThe FindClusters() function implements this procedure, and contains a resolution parameter that sets the ‘granularity’ of the downstream clustering, with increased values leading to a greater number of clusters.\n\nRun the following commands:\nseuratFindNeighbors &lt;- FindNeighbors(\n    dat2Scaled2Obj,\n    reduction = \"pca\",\n    dims = 1:25,\n    do.plot = FALSE,\n    graph.name = NULL,\n    k.param = 30\n)\n\nseuratFindClusters &lt;- FindClusters(object = seuratFindNeighbors)\n\n\n\n\nSeurat offers several non-linear dimensional reduction techniques, such as tSNE and UMAP, to visualize and explore these datasets.\nThe goal of these algorithms is to learn underlying structure in the dataset, in order to place similar cells together in low-dimensional space.\nTherefore, cells that are grouped together within graph-based clusters determined above should co-localize on these dimension reduction plots.\n\ndat2UMAP &lt;- RunUMAP(seuratFindClusters, reduction = \"pca\", dims = 1:25, n.neighbors = 30L, min.dist = 0.3, seed.use = 123456L)\n\nIf you see that we have used 25 PCs and n.neighbors as 30\nn.neighbors defines the number of nearest neighbors considered when constructing the UMAP graph.\nLarger values capture broader structures, while smaller values focus on finer details.\n\n\n\n\n\n\n\n\n\nn.neighbors Value\nEffect on UMAP\nWhen to Use?\n\n\n\n\nLow (5-15)\nCaptures local structure, fine details\nSmall datasets, cluster refinement\n\n\nDefault (30)\nBalanced between local and global structure\nGeneral use case\n\n\nHigh (50-100)\nPreserves global relationships, reduces fragmentation\nLarge datasets, broader clusters\n\n\n\nTo generate UMAP, run the following command:\nDimPlot(dat2UMAP, reduction = \"umap\")\n\n\n\n\n\nIn scRNA-seq experiments, doublets are artifactual libraries generated from two cells.\nDoublets are defined when two or more cells are mistakenly treated as a single cell.\nThey typically arise due to errors in cell sorting or capture, especially in droplet-based protocols involving thousands of cells.\nIn this workshop, we will be using DoubletFinder.\nIt is a tool used to detect and remove doublets (artificially merged cells) in scRNA-seq data.\nBelow is a step-by-step guide to doublet detection and removal in Seurat using DoubletFinder.\n\nStep 1: Install and Load Required Packages\nremotes::install_github('chris-mcginnis-ucsf/DoubletFinder')\nOnce the package is installed, the load the library.\nlibrary(DoubletFinder)\nStep 2: Parameter Sweeping for pK Selection\nSweep a range of parameters to find the optimal pK.\nsweep.res.list &lt;- paramSweep(dat2UMAP, PCs = 1:20, sct = TRUE)\nsweep.stats &lt;- summarizeSweep(sweep.res.list, GT = FALSE)\nbcmvn &lt;- find.pK(sweep.stats)\npk &lt;- as.numeric(as.vector(bcmvn$pK)[which.max(bcmvn$BCmetric)])\n\nparamSweep(): Tests multiple pK (parameter K) values using PCs 1 to 20.\nsummarizeSweep(): Summarizes results into a dataframe.\nfind.pK(): Finds the best pK using a “BCmetric” score.\nwhich.max(bcmvn$BCmetric): Selects the pK value with the highest BCmetric, as this gives the best separation between doublets and singlets.\n\nWhy do we need pK?\n\npK is a clustering resolution parameter that affects doublet detection.\nA higher BCmetric means better performance of a given pK.\n\nStep 3: Estimate the Expected Number of Doublets\nannotations &lt;- dat2UMAP@active.ident\nhomotypic.prop &lt;- modelHomotypic(annotations)\nnExp_poi &lt;- round(0.076 * length(dat2UMAP@active.ident))\nnExp_poi.adj &lt;- round(nExp_poi * (1 - homotypic.prop))\n\nmodelHomotypic(annotations): Estimates homotypic doublets (cells of the same type that are mistakenly identified as a doublet).\nnExp_poi &lt;- round(0.076 * length(p1tumorFilteredObj@active.ident)):\n\nUses 10X Genomics’ doublet rate formula: ~7.6% (0.076) × number of cells.\nThis gives the expected number of doublets (nExp_poi) in the dataset.\n\nnExp_poi.adj &lt;- round(nExp_poi * (1 - homotypic.prop))\n\nAdjusts for homotypic doublets to avoid over-filtering.\n\n\nWhy adjust for homotypic proportion?\n\nIf cells in a cluster are mostly from the same cell type, they might be misclassified as doublets.\nThis adjustment prevents over-filtering of true biological clusters.\n\nStep 4: Run DoubletFinder (First Pass)\nseuratDoublet &lt;- doubletFinder(dat2UMAP, PCs = 1:20, pN = 0.25, pK = pk, \n                               nExp = nExp_poi, reuse.pANN = FALSE, sct = TRUE)\n\nThis step assigns a probability score (pANN) to each cell, indicating how likely it is a doublet.\n\nStep 5: Prepare for Second Pass\npANN_String &lt;- paste(\"pANN_0.25_\", pk, \"_\", list(nExp_poi), sep=\"\")\n\nCreates a string name for the pANN column, which stores doublet probability scores.\n\nStep 6: Run DoubletFinder (Second Pass - Adjusted for Homotypic Doublets)\ndat2UMAPDoublet &lt;- doubletFinder(seuratDoublet, PCs = 1:10, pN = 0.25, pK = pk, \n                                        nExp = nExp_poi.adj, reuse.pANN = pANN_String)\n\nThe first pass identifies all doublets.\nThe second pass refines the classification by removing homotypic doublets.\n\nStep 7: Append doublets column in metadata\n# Use this format: DF.classifications_pN_pk_nExp_poi\n\n# Find out pk value\nprint(pk)\n\n# Find out nExp_poi value\nprint(nExp_poi)\n\n# Replace the DF.classifications_pN_pk_nExp_poi with the above values\n\n# For example, if pk is 0.24 and nExp_poi is 134, then execute the following command\n\nclassificationsCol &lt;- dat2UMAPDoublet@meta.data[\"DF.classifications_0.25_0.24_134\"]\n\ndat2UMAPDoublet@meta.data[,\"DF_hi.lo\"] &lt;- classificationsCol[1]\n\nNow, construct a UMAP displaying the Doublets and Singlets.\nYou can also generate Violin plot displaying the same information.\n\n\n\n\nRemove the doublets and select Singlets by performing the following command:\ndat2UMAPSinglets &lt;- subset(dat2UMAPDoublet, subset = DF_hi.lo == \"Singlet\")\nOnce the doublets are removed and singlets are selected, then re-run the following steps as performed above:\nsingletsNormalisedObj &lt;- NormalizeData(object = dat2UMAPSinglets, normalization.method = \"LogNormalize\", scale.factor = 10000)\nsingletsNormalised2Obj &lt;- FindVariableFeatures(singletsNormalisedObj, selection.method = \"vst\", nfeatures = 2000)\nall.genes &lt;- rownames(singletsNormalised2Obj)\nsingletsScaledObj &lt;- ScaleData(object = singletsNormalised2Obj, features = all.genes)\nsingletsScaled2Obj &lt;- RunPCA(object = singletsScaledObj, features = VariableFeatures(object = singletsScaledObj), do.print = TRUE, ndims.print = 1:5, nfeatures.print = 5)\nElbowPlot(singletsScaled2Obj, ndims = 50)\nseuratFindNeighbors &lt;- FindNeighbors(\n    singletsScaled2Obj,\n    reduction = \"pca\",\n    dims = 1:25,\n    do.plot = FALSE,\n    graph.name = NULL,\n    k.param = 30\n)\nsingletsFindClusters &lt;- FindClusters(object = singletsFindNeighbors)\nsingletsUMAP &lt;- RunUMAP(singletsFindClusters, reduction = \"pca\", dims = 1:25, n.neighbors = 30L, min.dist = 0.3, seed.use = 123456L)\nOnce the pre-processing steps are finished, construct the UMAP using the DimPlot function.\nDimPlot(singletsUMAP, reduction = \"umap\")\n\n\n\n\nThere are several data visualisation methods and functions in Seurat which are used for visualising marker feature expression.\nThis can be achieved using:\n\nFeaturePlot()\nDotPlot()\nVlnPlot()\nRidgePlot()\nDimPlot()\nDoHeatmap()\n\n\n\n\n\nThe FeaturePlot() function in Seurat is used to visualize the expression of one or more genes (features) on a UMAP.\nIt helps in identifying the spatial distribution of gene expression across clusters or cell populations.\n\nFeaturePlot(dat2UMAP, features = c(\"Slc26a4\", \"Slc34a1\", \"Slc8a1\", \"Ptpro\", \"Csmd1\", \"Top2a\"))\n\n\n\n\n\nThe DotPlot() function in Seurat is used to visualize the expression levels of multiple genes across different clusters in a dot plot format.\nIt is particularly useful for comparing marker gene expression across cell clusters and assigning cell types.\n\ngenes = c(\"Slc26a4\", \"Slc34a1\", \"Slc8a1\", \"Ptpro\", \"Csmd1\", \"Top2a\")\nDotPlot(dat2UMAP, features = genes) + RotatedAxis()\n\n\n\n\n\nThe VlnPlot() function in Seurat creates violin plots to visualize the distribution of gene expression levels across different clusters or groups of cells.\nIt helps in identifying differences in gene expression between clusters.\n\ngenes = c(\"Slc26a4\", \"Slc34a1\", \"Slc8a1\", \"Ptpro\", \"Csmd1\", \"Top2a\")\nVlnPlot(dat2UMAP, features = genes)\n\n\n\n\n\nThe RidgePlot() function in Seurat generates ridge plots to visualize the distribution of gene expression across different clusters or groups of cells.\nIt is useful for comparing the expression levels of genes in different cell populations.\n\ngenes = c(\"Slc26a4\", \"Slc34a1\", \"Slc8a1\", \"Ptpro\", \"Csmd1\", \"Top2a\")\nRidgePlot(dat2UMAP, features = genes, ncol = 2)\n\n\n\n\n\nThe DimPlot() function in Seurat is used to visualize cells in a reduced dimensional space (e.g., UMAP, t-SNE, or PCA) and color them based on their cluster identity or metadata attributes.\nIt is useful for identifying and interpreting cell populations in single-cell RNA-seq analysis.\n\nSyntax:\nDimPlot(object, reduction = \"umap\", group.by = \"ident\", label = TRUE, pt.size = 1)\nFor example-\nDimPlot(dat2UMAP, reduction = \"pca\")\n\n\n\n\n\nThe DoHeatmap() function in Seurat is used to generate a heatmap of gene expression across different cell clusters or groups.\nIt is particularly useful for visualizing the expression patterns of top marker genes across clusters.\n\nDoHeatmap(dat2UMAP, features = VariableFeatures(dat2UMAP)[1:100], cells = 1:500, size = 4,\n          angle = 90) + NoLegend()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "scrnaseqcourse",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#what-you-will-learn-on-this-course",
    "href": "index.html#what-you-will-learn-on-this-course",
    "title": "scrnaseqcourse",
    "section": "What you will learn on this course:",
    "text": "What you will learn on this course:\n\nBasic Unix commands\nWorking on HPC\nDownloading scrnaseq datasets and genome files.\nSetting up directory for the data processing and analysis.\nHow to run Nextflow pipeline on HPCs.\nHow to process 10x cellranger pipeline.\nHow to process and analyse scrnaseq count data in R.\nHow to visualise the analysed data and perform additional downstream analysis."
  },
  {
    "objectID": "index.html#introduction-to-single-cell-rna-seq",
    "href": "index.html#introduction-to-single-cell-rna-seq",
    "title": "scrnaseqcourse",
    "section": "Introduction to Single-Cell RNA-seq",
    "text": "Introduction to Single-Cell RNA-seq\n\nRNA-seq allows profiling the transcripts in a sample in an efficient and cost-effective way.\nPart of its success is due to the fact that RNA-seq allows for an unbiased sampling of all transcripts in a sample, rather than being limited to a pre-determined set of transcripts (as in microarrays or RT-qPCR).\nTypically, RNA-seq has been used in samples composed of a mixture of cells, referred to as bulk RNA-seq, and has many applications.\nFor example, it can be used to characterise expression signatures between tissues in healthy/diseased, wild-type/mutant or control/treated samples.\nHowever, with bulk RNA-seq we can only estimate the average expression level for each gene across a population of cells, without regard for the heterogeneity in gene expression across individual cells of that sample.\n\n\n\nUnlike with the bulk approach, with scRNA-seq we can estimate a distribution of expression levels for each gene across a population of cells.\nThis allows us to answer new biological questions where cell-specific changes in the transcriptome are important. For example discovering new or rare cell types, identifying differential cell composition between healthy/diseased tissues or understanding cell differentiation during development."
  },
  {
    "objectID": "index.html#sample-preparation-protocols",
    "href": "index.html#sample-preparation-protocols",
    "title": "scrnaseqcourse",
    "section": "Sample Preparation Protocols",
    "text": "Sample Preparation Protocols\nBroadly speaking, a typical scRNA-seq protocol consists of the following steps (illustrated in the figure below):\n\nTissue dissection and cell dissociating to obtain a suspension of cells.\nOptionally cells may be selected\nCapture single cells into individual reaction containers (e.g. wells or oil droplets).\nExtracting the RNA from each cell.\nReverse-transcribing the RNA to more stable cDNA.\nAmplifying the cDNA (either by in vitro transcription or by PCR).\nPreparing the sequencing library with adequate molecular adapters.\nSequencing, usually with paired-end Illumina protocols.\nProcessing the raw data to obtain a count matrix of genes-by-cells\nCarrying several downstream analysis (the focus of this course)."
  },
  {
    "objectID": "index.html#unix-configuration",
    "href": "index.html#unix-configuration",
    "title": "scrnaseqcourse",
    "section": "Unix: Configuration",
    "text": "Unix: Configuration\n\nUnix: Hardware\n\nHardware: the physical components (the bits you can see when you take the back off a computer.\nCPU (central processing unit): the computer chip performing the calculations.\n\nHard drive: saved storage – your saved files.\nRAM (random access memory): like the hard drive, it stores information. Access (reading this information) is faster than the hard drive, although information is only present whilst the compute is powered on, i.e. this is memory space.\n\n\n\n\nUnix: Kernel\n\nThe kernel sits between the command line and the hardware.\n\nWhen you type a command line to the screen and hit “enter,” the kernel executes the command, allocating the appropriate time and memory to the task.\n\n\n\nUnix: Commands\n\nthe commands are the bread-and-butter functions common to all Linux installations and are part of the core (minimal) install.\nthey perform core processes such as file and job manipulations (read, write, delete files/jobs).\n\n\n\nUnix: Programs\n\nOther programs work identically to the core commands.\nThey are different because they generally perform specialised functions, for example, mapping next-generation sequence to a genome assembly."
  },
  {
    "objectID": "index.html#basic-unix-graphical-user-interface-gui-command-lineshell",
    "href": "index.html#basic-unix-graphical-user-interface-gui-command-lineshell",
    "title": "scrnaseqcourse",
    "section": "Basic Unix: Graphical User Interface (GUI) & Command Line/Shell",
    "text": "Basic Unix: Graphical User Interface (GUI) & Command Line/Shell\n\nAll Windows/Mac/Linux PC’s use a GUI to allow users to easily navigate and use the PC.\nThe GUI is common to Window/Mac/Linux.\n\nThe interface permits you to access files and run commands/programs by clicking icon/apps, drag-and-drop.\n\nThis is a shell. We can use this to type commands etc.\n\nIn simple terms, the window on the computer into which you type a command, is called the shell"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]